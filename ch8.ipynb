{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-20T06:30:33.498096Z",
     "start_time": "2024-10-20T06:30:33.489646Z"
    }
   },
   "source": "1+1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T06:32:57.672325Z",
     "start_time": "2024-10-20T06:32:41.226328Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "\n",
    "def make_prompt(ddl, question, query=''):\n",
    "    prompt = f\"\"\"당신은 SQL을 생성하는 SQL 봇입니다. DDL의 테이블을 활용한 Question을 해결할 수 있는 SQL 쿼리를 생성하세요.\n",
    "\n",
    "### DDL:\n",
    "{ddl}\n",
    "\n",
    "### Question:\n",
    "{question}\n",
    "\n",
    "### SQL:\n",
    "{query}\n",
    "\"\"\"\n",
    "    return prompt\n",
    "\n",
    "dataset = load_dataset(\"shangrilar/ko_text2sql\", \"origin\")['test']\n",
    "dataset = dataset.to_pandas()\n",
    "\n",
    "for idx, row in dataset.iterrows():\n",
    "    prompt = make_prompt(row['context'], row['question'])\n",
    "    dataset.loc[idx, 'prompt'] = prompt\n"
   ],
   "id": "91f4dfa58d90cbe9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/281 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1e43b08ea830466ea8d68294718ffc8e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Downloading data:   0%|          | 0.00/25.6M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3206fcfdcfd3406c8b85473c231c30dd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Downloading data:   0%|          | 0.00/61.1k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "029d6564ab5444cd8c8ab409009f8522"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating train split:   0%|          | 0/38246 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0e611b45c30b4b899ac2cd14e8aa2067"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating test split:   0%|          | 0/112 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "29c6f9a9f7654f5b9688b92f8745c3ee"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T06:33:01.369937Z",
     "start_time": "2024-10-20T06:33:01.357472Z"
    }
   },
   "cell_type": "code",
   "source": "dataset",
   "id": "81ccc238184ea680",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     db_id                                            context  \\\n",
       "0        1  CREATE TABLE quests (\\n  quest_id INT PRIMARY ...   \n",
       "1        1  CREATE TABLE players (\\n  player_id INT PRIMAR...   \n",
       "2        1  CREATE TABLE quests (\\n  quest_id INT PRIMARY ...   \n",
       "3        1  CREATE TABLE characters (\\n  character_id INT ...   \n",
       "4        1  CREATE TABLE characters (\\n  character_id INT ...   \n",
       "..     ...                                                ...   \n",
       "107      1  CREATE TABLE quests (\\n  quest_id INT PRIMARY ...   \n",
       "108      1  CREATE TABLE characters (\\n  character_id INT ...   \n",
       "109      1  CREATE TABLE npcs (\\n  npc_id INT PRIMARY KEY ...   \n",
       "110      1  CREATE TABLE characters (\\n  character_id INT ...   \n",
       "111      1  CREATE TABLE characters (\\n  character_id INT ...   \n",
       "\n",
       "                                              question  \\\n",
       "0                            각 보상 아이템별로 보상 경험치의 합을 구해줘   \n",
       "1               사용자 이름에 'admin'이 포함되어 있는 계정의 수를 알려주세요.   \n",
       "2             퀘스트 진행 상황이 100%인 퀘스트의 이름과 보상 경험치는 얼마인가요?   \n",
       "3             경험이 5000000 이상이거나 직업이 전사인 캐릭터들의 이름은 무엇인가   \n",
       "4       레벨이 20 이상인 플레이어의 캐릭터 이름과 해당 캐릭터의 스킬 이름을 알아보세요.   \n",
       "..                                                 ...   \n",
       "107  캐릭터가 완료한 퀘스트 중 보상 경험치가 100 이상 200 이하인 퀘스트의 이름과...   \n",
       "108  경험이 1000에서 2000 사이인 캐릭터들의 이름, 레벨, 경험치, 아이템 이름 ...   \n",
       "109                            각 역할별로 npc의 총 수를 알려주세요.   \n",
       "110          장비가 장착된 상태인 캐릭터의 플레이어 ID와 아이템 이름을 나열하십시오.   \n",
       "111     인벤토리 아이템의 이름과 수량, 해당 아이템을 소유한 캐릭터의 클래스를 보여주세요.   \n",
       "\n",
       "                                                answer  \\\n",
       "0    SELECT reward_items, SUM(reward_experience) AS...   \n",
       "1    SELECT COUNT(*) FROM players WHERE username LI...   \n",
       "2    SELECT q.name, q.reward_experience FROM quests...   \n",
       "3    SELECT name FROM characters WHERE experience >...   \n",
       "4    SELECT C.name, ST.skill_name FROM characters A...   \n",
       "..                                                 ...   \n",
       "107  SELECT q.name, q.reward_items FROM quests AS q...   \n",
       "108  SELECT c.name, c.level, c.experience, i.item_n...   \n",
       "109  SELECT role, COUNT(npc_id) FROM npcs GROUP BY ...   \n",
       "110  SELECT T1.player_id, T2.item_name FROM charact...   \n",
       "111  SELECT T2.item_name, T2.quantity, T1.character...   \n",
       "\n",
       "                                                prompt  \n",
       "0    당신은 SQL을 생성하는 SQL 봇입니다. DDL의 테이블을 활용한 Question...  \n",
       "1    당신은 SQL을 생성하는 SQL 봇입니다. DDL의 테이블을 활용한 Question...  \n",
       "2    당신은 SQL을 생성하는 SQL 봇입니다. DDL의 테이블을 활용한 Question...  \n",
       "3    당신은 SQL을 생성하는 SQL 봇입니다. DDL의 테이블을 활용한 Question...  \n",
       "4    당신은 SQL을 생성하는 SQL 봇입니다. DDL의 테이블을 활용한 Question...  \n",
       "..                                                 ...  \n",
       "107  당신은 SQL을 생성하는 SQL 봇입니다. DDL의 테이블을 활용한 Question...  \n",
       "108  당신은 SQL을 생성하는 SQL 봇입니다. DDL의 테이블을 활용한 Question...  \n",
       "109  당신은 SQL을 생성하는 SQL 봇입니다. DDL의 테이블을 활용한 Question...  \n",
       "110  당신은 SQL을 생성하는 SQL 봇입니다. DDL의 테이블을 활용한 Question...  \n",
       "111  당신은 SQL을 생성하는 SQL 봇입니다. DDL의 테이블을 활용한 Question...  \n",
       "\n",
       "[112 rows x 5 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>db_id</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>CREATE TABLE quests (\\n  quest_id INT PRIMARY ...</td>\n",
       "      <td>각 보상 아이템별로 보상 경험치의 합을 구해줘</td>\n",
       "      <td>SELECT reward_items, SUM(reward_experience) AS...</td>\n",
       "      <td>당신은 SQL을 생성하는 SQL 봇입니다. DDL의 테이블을 활용한 Question...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>CREATE TABLE players (\\n  player_id INT PRIMAR...</td>\n",
       "      <td>사용자 이름에 'admin'이 포함되어 있는 계정의 수를 알려주세요.</td>\n",
       "      <td>SELECT COUNT(*) FROM players WHERE username LI...</td>\n",
       "      <td>당신은 SQL을 생성하는 SQL 봇입니다. DDL의 테이블을 활용한 Question...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>CREATE TABLE quests (\\n  quest_id INT PRIMARY ...</td>\n",
       "      <td>퀘스트 진행 상황이 100%인 퀘스트의 이름과 보상 경험치는 얼마인가요?</td>\n",
       "      <td>SELECT q.name, q.reward_experience FROM quests...</td>\n",
       "      <td>당신은 SQL을 생성하는 SQL 봇입니다. DDL의 테이블을 활용한 Question...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>CREATE TABLE characters (\\n  character_id INT ...</td>\n",
       "      <td>경험이 5000000 이상이거나 직업이 전사인 캐릭터들의 이름은 무엇인가</td>\n",
       "      <td>SELECT name FROM characters WHERE experience &gt;...</td>\n",
       "      <td>당신은 SQL을 생성하는 SQL 봇입니다. DDL의 테이블을 활용한 Question...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>CREATE TABLE characters (\\n  character_id INT ...</td>\n",
       "      <td>레벨이 20 이상인 플레이어의 캐릭터 이름과 해당 캐릭터의 스킬 이름을 알아보세요.</td>\n",
       "      <td>SELECT C.name, ST.skill_name FROM characters A...</td>\n",
       "      <td>당신은 SQL을 생성하는 SQL 봇입니다. DDL의 테이블을 활용한 Question...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>1</td>\n",
       "      <td>CREATE TABLE quests (\\n  quest_id INT PRIMARY ...</td>\n",
       "      <td>캐릭터가 완료한 퀘스트 중 보상 경험치가 100 이상 200 이하인 퀘스트의 이름과...</td>\n",
       "      <td>SELECT q.name, q.reward_items FROM quests AS q...</td>\n",
       "      <td>당신은 SQL을 생성하는 SQL 봇입니다. DDL의 테이블을 활용한 Question...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>1</td>\n",
       "      <td>CREATE TABLE characters (\\n  character_id INT ...</td>\n",
       "      <td>경험이 1000에서 2000 사이인 캐릭터들의 이름, 레벨, 경험치, 아이템 이름 ...</td>\n",
       "      <td>SELECT c.name, c.level, c.experience, i.item_n...</td>\n",
       "      <td>당신은 SQL을 생성하는 SQL 봇입니다. DDL의 테이블을 활용한 Question...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>1</td>\n",
       "      <td>CREATE TABLE npcs (\\n  npc_id INT PRIMARY KEY ...</td>\n",
       "      <td>각 역할별로 npc의 총 수를 알려주세요.</td>\n",
       "      <td>SELECT role, COUNT(npc_id) FROM npcs GROUP BY ...</td>\n",
       "      <td>당신은 SQL을 생성하는 SQL 봇입니다. DDL의 테이블을 활용한 Question...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>1</td>\n",
       "      <td>CREATE TABLE characters (\\n  character_id INT ...</td>\n",
       "      <td>장비가 장착된 상태인 캐릭터의 플레이어 ID와 아이템 이름을 나열하십시오.</td>\n",
       "      <td>SELECT T1.player_id, T2.item_name FROM charact...</td>\n",
       "      <td>당신은 SQL을 생성하는 SQL 봇입니다. DDL의 테이블을 활용한 Question...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>1</td>\n",
       "      <td>CREATE TABLE characters (\\n  character_id INT ...</td>\n",
       "      <td>인벤토리 아이템의 이름과 수량, 해당 아이템을 소유한 캐릭터의 클래스를 보여주세요.</td>\n",
       "      <td>SELECT T2.item_name, T2.quantity, T1.character...</td>\n",
       "      <td>당신은 SQL을 생성하는 SQL 봇입니다. DDL의 테이블을 활용한 Question...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112 rows × 5 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T06:51:48.418286Z",
     "start_time": "2024-10-20T06:35:33.119150Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "\n",
    "model_id = 'shangrilar/yi-ko-6b-text2sql'\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, device_map='auto', load_in_4bit=True, bnb_4bit_compute_dtype=torch.float16)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "hf_pipeline = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)"
   ],
   "id": "6887e07d0f2b461a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/694 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f2ce62df9e6d461380aeccab67526c80"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kmr34\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:148: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\kmr34\\.cache\\huggingface\\hub\\models--shangrilar--yi-ko-6b-text2sql. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "68cbd122b1b2425a92774c33509dc352"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ca24979176374eb2a096c43c8e23d53e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model-00001-of-00003.safetensors:   0%|          | 0.00/4.96G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4a5ccc6688014cc9a5c51c0da0ef6292"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model-00002-of-00003.safetensors:   0%|          | 0.00/4.93G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "390b0dac789645c0acc0948e8a989c88"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model-00003-of-00003.safetensors:   0%|          | 0.00/2.46G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ac9dcfb766424d33b981e568f57e0744"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to import transformers.integrations.bitsandbytes because of the following error (look up to see its traceback):\ncannot import name 'get_available_devices' from 'transformers.utils' (C:\\Users\\kmr34\\anaconda3\\Lib\\site-packages\\transformers\\utils\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1510\u001B[0m, in \u001B[0;36m_get_module\u001B[1;34m(self, module_name)\u001B[0m\n\u001B[0;32m   1506\u001B[0m \u001B[38;5;66;03m# docstyle-ignore\u001B[39;00m\n\u001B[0;32m   1507\u001B[0m CCL_IMPORT_ERROR \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\"\"\u001B[39m\n\u001B[0;32m   1508\u001B[0m \u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m requires the torch ccl library but it was not found in your environment. You can install it with pip:\u001B[39m\n\u001B[0;32m   1509\u001B[0m \u001B[38;5;124m`pip install oneccl_bind_pt -f https://developer.intel.com/ipex-whl-stable`\u001B[39m\n\u001B[1;32m-> 1510\u001B[0m \u001B[38;5;124mPlease note that you may need to restart your runtime after installation.\u001B[39m\n\u001B[0;32m   1511\u001B[0m \u001B[38;5;124m\"\"\"\u001B[39m\n\u001B[0;32m   1513\u001B[0m \u001B[38;5;66;03m# docstyle-ignore\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\importlib\\__init__.py:90\u001B[0m, in \u001B[0;36mimport_module\u001B[1;34m(name, package)\u001B[0m\n\u001B[0;32m     89\u001B[0m         level \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m---> 90\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _bootstrap\u001B[38;5;241m.\u001B[39m_gcd_import(name[level:], package, level)\n",
      "File \u001B[1;32m<frozen importlib._bootstrap>:1387\u001B[0m, in \u001B[0;36m_gcd_import\u001B[1;34m(name, package, level)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap>:1360\u001B[0m, in \u001B[0;36m_find_and_load\u001B[1;34m(name, import_)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap>:1331\u001B[0m, in \u001B[0;36m_find_and_load_unlocked\u001B[1;34m(name, import_)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap>:935\u001B[0m, in \u001B[0;36m_load_unlocked\u001B[1;34m(spec)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap_external>:995\u001B[0m, in \u001B[0;36mexec_module\u001B[1;34m(self, module)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap>:488\u001B[0m, in \u001B[0;36m_call_with_frames_removed\u001B[1;34m(f, *args, **kwds)\u001B[0m\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\integrations\\bitsandbytes.py:9\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpackaging\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m version\n\u001B[1;32m----> 9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m     10\u001B[0m     get_available_devices,\n\u001B[0;32m     11\u001B[0m     is_accelerate_available,\n\u001B[0;32m     12\u001B[0m     is_bitsandbytes_available,\n\u001B[0;32m     13\u001B[0m     is_bitsandbytes_multi_backend_available,\n\u001B[0;32m     14\u001B[0m     is_ipex_available,\n\u001B[0;32m     15\u001B[0m     is_torch_available,\n\u001B[0;32m     16\u001B[0m     logging,\n\u001B[0;32m     17\u001B[0m )\n\u001B[0;32m     20\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_bitsandbytes_available():\n",
      "\u001B[1;31mImportError\u001B[0m: cannot import name 'get_available_devices' from 'transformers.utils' (C:\\Users\\kmr34\\anaconda3\\Lib\\site-packages\\transformers\\utils\\__init__.py)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 4\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtransformers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m AutoTokenizer, AutoModelForCausalLM, pipeline\n\u001B[0;32m      3\u001B[0m model_id \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mshangrilar/yi-ko-6b-text2sql\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m----> 4\u001B[0m model \u001B[38;5;241m=\u001B[39m AutoModelForCausalLM\u001B[38;5;241m.\u001B[39mfrom_pretrained(model_id, device_map\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mauto\u001B[39m\u001B[38;5;124m'\u001B[39m, load_in_4bit\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, bnb_4bit_compute_dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mfloat16)\n\u001B[0;32m      5\u001B[0m tokenizer \u001B[38;5;241m=\u001B[39m AutoTokenizer\u001B[38;5;241m.\u001B[39mfrom_pretrained(model_id)\n\u001B[0;32m      6\u001B[0m hf_pipeline \u001B[38;5;241m=\u001B[39m pipeline(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtext-generation\u001B[39m\u001B[38;5;124m\"\u001B[39m, model\u001B[38;5;241m=\u001B[39mmodel, tokenizer\u001B[38;5;241m=\u001B[39mtokenizer)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:563\u001B[0m, in \u001B[0;36mfrom_pretrained\u001B[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001B[0m\n\u001B[0;32m    559\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m model_class\u001B[38;5;241m.\u001B[39mfrom_pretrained(\n\u001B[0;32m    560\u001B[0m         pretrained_model_name_or_path, \u001B[38;5;241m*\u001B[39mmodel_args, config\u001B[38;5;241m=\u001B[39mconfig, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mhub_kwargs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[0;32m    561\u001B[0m     )\n\u001B[0;32m    562\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mtype\u001B[39m(config) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_model_mapping\u001B[38;5;241m.\u001B[39mkeys():\n\u001B[1;32m--> 563\u001B[0m     model_class \u001B[38;5;241m=\u001B[39m _get_model_class(config, \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_model_mapping)\n\u001B[0;32m    564\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m model_class\u001B[38;5;241m.\u001B[39mfrom_pretrained(\n\u001B[0;32m    565\u001B[0m         pretrained_model_name_or_path, \u001B[38;5;241m*\u001B[39mmodel_args, config\u001B[38;5;241m=\u001B[39mconfig, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mhub_kwargs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[0;32m    566\u001B[0m     )\n\u001B[0;32m    567\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    568\u001B[0m     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnrecognized configuration class \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mconfig\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m for this kind of AutoModel: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    569\u001B[0m     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mModel type should be one of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(c\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mfor\u001B[39;00m\u001B[38;5;250m \u001B[39mc\u001B[38;5;250m \u001B[39m\u001B[38;5;129;01min\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_model_mapping\u001B[38;5;241m.\u001B[39mkeys())\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    570\u001B[0m )\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\modeling_utils.py:3564\u001B[0m, in \u001B[0;36mfrom_pretrained\u001B[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001B[0m\n\u001B[0;32m   3558\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mEnvironmentError\u001B[39;00m(\n\u001B[0;32m   3559\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mError no file named \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m_add_variant(WEIGHTS_NAME,\u001B[38;5;250m \u001B[39mvariant)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m_add_variant(SAFE_WEIGHTS_NAME,\u001B[38;5;250m \u001B[39mvariant)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m,\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   3560\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mTF2_WEIGHTS_NAME\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mTF_WEIGHTS_NAME\u001B[38;5;250m \u001B[39m\u001B[38;5;241m+\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.index\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m or \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mFLAX_WEIGHTS_NAME\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m found in directory\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   3561\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpretrained_model_name_or_path\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   3562\u001B[0m         )\n\u001B[0;32m   3563\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39misfile(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(subfolder, pretrained_model_name_or_path)):\n\u001B[1;32m-> 3564\u001B[0m     archive_file \u001B[38;5;241m=\u001B[39m pretrained_model_name_or_path\n\u001B[0;32m   3565\u001B[0m     is_local \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m   3566\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39misfile(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(subfolder, pretrained_model_name_or_path \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.index\u001B[39m\u001B[38;5;124m\"\u001B[39m)):\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\quantizers\\base.py:182\u001B[0m, in \u001B[0;36mHfQuantizer.preprocess_model\u001B[1;34m(self, model, **kwargs)\u001B[0m\n\u001B[0;32m    180\u001B[0m model\u001B[38;5;241m.\u001B[39mis_quantized \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m    181\u001B[0m model\u001B[38;5;241m.\u001B[39mquantization_method \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mquantization_config\u001B[38;5;241m.\u001B[39mquant_method\n\u001B[1;32m--> 182\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_process_model_before_weight_loading(model, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\quantizers\\quantizer_bnb_4bit.py:262\u001B[0m, in \u001B[0;36m_process_model_before_weight_loading\u001B[1;34m(self, model, device_map, keep_in_fp32_modules, **kwargs)\u001B[0m\n\u001B[0;32m    259\u001B[0m         torch_dtype = torch.float16\n\u001B[0;32m    260\u001B[0m     return torch_dtype\n\u001B[1;32m--> 262\u001B[0m # Copied from transformers.quantizers.quantizer_bnb_8bit.Bnb8BitHfQuantizer.update_device_map\n\u001B[0;32m    263\u001B[0m def update_device_map(self, device_map):\n\u001B[0;32m    264\u001B[0m     if device_map is None:\n",
      "File \u001B[1;32m<frozen importlib._bootstrap>:1412\u001B[0m, in \u001B[0;36m_handle_fromlist\u001B[1;34m(module, fromlist, import_, recursive)\u001B[0m\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1500\u001B[0m, in \u001B[0;36m__getattr__\u001B[1;34m(self, name)\u001B[0m\n\u001B[0;32m   1494\u001B[0m PYCTCDECODE_IMPORT_ERROR \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\"\"\u001B[39m\n\u001B[0;32m   1495\u001B[0m \u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m requires the pyctcdecode library but it was not found in your environment. You can install it with pip:\u001B[39m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;124m`pip install pyctcdecode`. Please note that you may need to restart your runtime after installation.\u001B[39m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;124m\"\"\"\u001B[39m\n\u001B[0;32m   1499\u001B[0m \u001B[38;5;66;03m# docstyle-ignore\u001B[39;00m\n\u001B[1;32m-> 1500\u001B[0m ACCELERATE_IMPORT_ERROR \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\"\"\u001B[39m\n\u001B[0;32m   1501\u001B[0m \u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m requires the accelerate library >= \u001B[39m\u001B[38;5;132;01m{ACCELERATE_MIN_VERSION}\u001B[39;00m\u001B[38;5;124m it was not found in your environment.\u001B[39m\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;124mYou can install or update it with pip: `pip install --upgrade accelerate`. Please note that you may need to restart your\u001B[39m\n\u001B[0;32m   1503\u001B[0m \u001B[38;5;124mruntime after installation.\u001B[39m\n\u001B[0;32m   1504\u001B[0m \u001B[38;5;124m\"\"\"\u001B[39m\n\u001B[0;32m   1506\u001B[0m \u001B[38;5;66;03m# docstyle-ignore\u001B[39;00m\n\u001B[0;32m   1507\u001B[0m CCL_IMPORT_ERROR \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\"\"\u001B[39m\n\u001B[0;32m   1508\u001B[0m \u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m requires the torch ccl library but it was not found in your environment. You can install it with pip:\u001B[39m\n\u001B[0;32m   1509\u001B[0m \u001B[38;5;124m`pip install oneccl_bind_pt -f https://developer.intel.com/ipex-whl-stable`\u001B[39m\n\u001B[0;32m   1510\u001B[0m \u001B[38;5;124mPlease note that you may need to restart your runtime after installation.\u001B[39m\n\u001B[0;32m   1511\u001B[0m \u001B[38;5;124m\"\"\"\u001B[39m\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1512\u001B[0m, in \u001B[0;36m_get_module\u001B[1;34m(self, module_name)\u001B[0m\n\u001B[0;32m      0\u001B[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Failed to import transformers.integrations.bitsandbytes because of the following error (look up to see its traceback):\ncannot import name 'get_available_devices' from 'transformers.utils' (C:\\Users\\kmr34\\anaconda3\\Lib\\site-packages\\transformers\\utils\\__init__.py)"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import time\n",
    "for batch_size in [1,2,4,8,16,32]:\n",
    "    start_time = time.time()\n",
    "    hf_pipeline(dataset['prompt'].tolist(), max_new_tokens=128, batch_size=batch_size)\n",
    "    print(f'{batch_size}: {time.time() - start_time}')"
   ],
   "id": "d72e7d739e073338"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from vllm import LLM, SamplingParams\n",
    "\n",
    "model_id = \"shangrilar/yi-ko-6b-text2sql\"\n",
    "llm = LLM(model=model_id, dtype=torch.float16, max_model_len=1024)"
   ],
   "id": "9f4c111970d24e4a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "for max_num_seqs in [1,2,4,8,16,32]:\n",
    "    start_time = time.time()\n",
    "    llm.llm_engine.scheduler_config.max_num_seq = max_num_seqs\n",
    "    sampling_params = SamplingParams(temperature=1, top_p=1, max_tokens=128)\n",
    "    outputs = llm.generate(dataset['prompt'].tolist(), sampling_params)\n",
    "    print(f'{max_num_seqs}: {time.time() - start_time}')"
   ],
   "id": "453ff2982f54ea42"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T09:25:31.409874Z",
     "start_time": "2024-10-20T09:25:28.775612Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "a6a9e15ceed69065",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Invalid requirement: 'chromadb=0.5.0'\n",
      "Hint: = is not a valid operator. Did you mean == ?\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ae12b2ed07b1439c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
